{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Yolo_Image_Process.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/carsonljc/APS360-Project/blob/master/Detector/Yolo_Image_Process.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CAgNd9ERijve",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from PIL import Image\n",
        "import os\n",
        "import re\n",
        "import glob\n",
        "import os.path\n",
        "import json"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jn31ni7Spp-0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "9014fe00-9780-480e-fe08-d7fae5ea0dbe"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n435Kli9ppqV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Unzip from drive\n",
        "%%capture\n",
        "!unzip /content/drive/'My Drive'/APS360/yolov3/train.zip -d /content/old_train/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q5k-WCxPpOJH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        },
        "outputId": "43487104-ec88-44e2-c943-7c2e681ff473"
      },
      "source": [
        "!pip install gdown"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: gdown in /usr/local/lib/python3.6/dist-packages (3.6.4)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from gdown) (4.41.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from gdown) (2.23.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from gdown) (1.15.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->gdown) (2020.6.20)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->gdown) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->gdown) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->gdown) (2.10)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-YySimmNSPfS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "63950ebc-f969-4a19-dcd5-e5d564c7c39e"
      },
      "source": [
        "#Unzip from link\n",
        "!gdown --id 17vMkoPZSibult22BsN49Vm5osuROahaM --output sample.zip \n",
        "!unzip -q sample.zip -d /content/Mapillary"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=17vMkoPZSibult22BsN49Vm5osuROahaM\n",
            "To: /content/sample.zip\n",
            "15.9GB [04:08, 64.1MB/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nugazgmzkA5M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.utils.data as data\n",
        "from torch import nn\n",
        "from torchvision import datasets, transforms\n",
        "\n",
        "class AnnotationDataSet(data.Dataset):\n",
        "    def __init__(self, path_to_imgs, path_to_json, transform = None):\n",
        "        self.path_to_imgs = path_to_imgs\n",
        "        self.path_to_json = path_to_json\n",
        "        self.image_ids = os.listdir(path_to_imgs)\n",
        "        self.transform = transform\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_id = self.image_ids[idx]\n",
        "        img_id = os.path.splitext(img_id)[0]\n",
        "        img = Image.open(os.path.join(self.path_to_imgs, img_id + \".jpg\"))\n",
        "        json_file = json.load(open(os.path.join(self.path_to_json, img_id + \".json\")))\n",
        "\n",
        "\n",
        "        if self.transform:\n",
        "            img = self.transform(img)\n",
        "\n",
        "        return img, json_file, img_id\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_ids)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6DOSapM6kFFp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def construct_YOLO_labels (json_file, img_width, img_height):\n",
        "\n",
        "  #Currently Assumes images are 3024 x 4032 (y, x)\n",
        "  #TODO: Change hard code in this function!\n",
        "\n",
        "  #Label in the format: [grid y coordinate][grid x coordinate][info]\n",
        "  #info[0] - sign present, [1] - Bbox X, [2] - Bbox Y, [3] - Bbox W, [4] - Bbox H\n",
        "  #all Bbox values are relative to size of a grid \n",
        "  #grid size currently 168x168 pixels \n",
        "\n",
        "\n",
        "  label = np.zeros([len(json_file[\"objects\"]), 5])\n",
        "  count = 0;\n",
        "\n",
        "  for i in json_file[\"objects\"]:\n",
        "\n",
        "    x_center = (i[\"bbox\"]['xmax'] - i[\"bbox\"]['xmin'])/2 +  i[\"bbox\"]['xmin']\n",
        "    y_center = (i[\"bbox\"]['ymax'] - i[\"bbox\"]['ymin'])/2 + i[\"bbox\"]['ymin']\n",
        "\n",
        "    x_center = x_center / img_width\n",
        "    y_center = y_center / img_height\n",
        "\n",
        "    #x_index = int(x_center / grid_width)\n",
        "    #y_index = int(y_center / grid_height)\n",
        "\n",
        "\n",
        "    width = (i[\"bbox\"]['xmax'] - i[\"bbox\"]['xmin']) / img_width \n",
        "    height = (i[\"bbox\"]['ymax'] - i[\"bbox\"]['ymin']) / img_height\n",
        "\n",
        "    #sign_type = -1\n",
        "    #regulatory_check = \"regulatory\"\n",
        "    #warning_check = \"warning\"\n",
        "    #information_check = \"information\"\n",
        "    #complementary_check = \"complementary\"\n",
        "    #other_check = \"other\"\n",
        "    #if (regulatory_check in i[\"label\"]):\n",
        "    #  sign_type = 0\n",
        "    #elif (warning_check in  i[\"label\"]):\n",
        "    #  sign_type = 1\n",
        "    #elif (information_check in i[\"label\"]):\n",
        "    #  sign_type = 2\n",
        "    #elif (complementary_check in i[\"label\"]):\n",
        "    #  sign_type = 3\n",
        "    #elif (other_check in i[\"label\"]):\n",
        "    #  sign_type = 4\n",
        "\n",
        "    valid_signs = ['regulatory--no-parking--g2', 'regulatory--maximum-speed-limit-55--g2', 'warning--road-narrows-left--g2', 'regulatory--maximum-speed-limit-25--g2', 'warning--pedestrians-crossing--g4', 'warning--roundabout--g2', 'regulatory--keep-left--g2', 'regulatory--do-not-block-intersection--g1', 'regulatory--turn-left--g2', 'regulatory--stop--g1', 'warning--steep-descent--g2', 'complementary--obstacle-delineator--g1', 'regulatory--one-way-right--g3', 'warning--narrow-bridge--g1', 'warning--turn-right--g1', 'warning--t-roads--g2', 'regulatory--wrong-way--g1', 'warning--crossroads--g3', 'regulatory--maximum-speed-limit-30--g3', 'information--disabled-persons--g1', 'regulatory--go-straight--g3', 'regulatory--yield--g1', 'information--gas-station--g1', 'regulatory--no-heavy-goods-vehicles--g2', 'complementary--chevron-right--g1', 'regulatory--no-entry--g1', 'information--highway-exit--g1', 'complementary--tow-away-zone--g1', 'warning--traffic-merges-right--g1', 'regulatory--no-overtaking--g5', 'warning--junction-with-a-side-road-perpendicular-right--g3', 'warning--road-narrows--g2', 'regulatory--no-right-turn--g1', 'warning--turn-left--g1', 'warning--school-zone--g2', 'regulatory--no-straight-through--g1', 'information--hospital--g1', 'regulatory--no-u-turn--g1', 'regulatory--one-way-left--g3', 'warning--road-narrows-right--g2', 'regulatory--maximum-speed-limit-45--g3', 'complementary--both-directions--g1', 'regulatory--no-bicycles--g2', 'warning--winding-road-first-left--g1', 'regulatory--dual-lanes-go-straight-on-right--g1', 'regulatory--triple-lanes-turn-left-center-lane--g1', 'warning--traffic-merges-left--g1', 'warning--traffic-signals--g3', 'warning--y-roads--g1', 'information--telephone--g1', 'complementary--chevron-left--g1', 'regulatory--reversible-lanes--g2', 'warning--winding-road-first-right--g1', 'warning--double-curve-first-right--g2', 'regulatory--maximum-speed-limit-100--g3', 'regulatory--maximum-speed-limit-35--g2', 'regulatory--no-buses--g3', 'information--airport--g2', 'warning--curve-left--g2', 'warning--curve-right--g2', 'regulatory--turn-right--g3', 'warning--junction-with-a-side-road-perpendicular-left--g3', 'warning--double-curve-first-left--g2', 'regulatory--no-turn-on-red--g2', 'regulatory--dual-lanes-go-straight-on-left--g1', 'regulatory--no-left-turn--g2', 'regulatory--road-closed--g2', 'warning--divided-highway-ends--g2', 'warning--height-restriction--g2', 'complementary--obstacle-delineator--g2', 'regulatory--maximum-speed-limit-40--g3', 'information--bike-route--g1', 'regulatory--no-pedestrians--g2', 'regulatory--keep-right--g4', 'regulatory--go-straight-or-turn-left--g2']\n",
        "    sign_type = 1\n",
        "\n",
        "    for valid_sign in valid_signs:\n",
        "      if (i[\"label\"] in valid_sign):\n",
        "        sign_type = 0\n",
        "        break\n",
        "    label[count] = np.array([sign_type, x_center, y_center, width, height])\n",
        "    count += 1\n",
        "  return label"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zr9FWrYUkLyd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sample_set = AnnotationDataSet(\"/content/split_hand_selected/train/images\", \"/content/split_hand_selected/train/annotations\", transform=transforms.ToTensor())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sLUBi_lVksf5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "bfc8d62d-6489-4365-966f-dbab3707f1db"
      },
      "source": [
        "%cd /content/split_hand_selected/train/images"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/split_hand_selected/train/images\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UuBifGVfndaN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "for img, json_file, img_id in iter(sample_set):\n",
        "  #print (img.shape)\n",
        "  label = construct_YOLO_labels(json_file, img.shape[2], img.shape[1])\n",
        "  newline = 0\n",
        "  file_name = img_id + \".txt\"\n",
        "  file = open(file_name, \"w\") \n",
        "  for i in label:\n",
        "    #### \n",
        "    if (i[0] == 0): #Don't include \"other-signs\"\n",
        "      if (newline):\n",
        "        file.write(\"\\n\")\n",
        "      #print (i)\n",
        "      str_content = \"{0:1d} {1:.6f} {2:.6f} {3:.6f} {4:.6f}\".format(int(i[0]), i[1], i[2], i[3], i[4])\n",
        "      file.write(str_content) \n",
        "      newline = 1\n",
        "    ###\n",
        "  file.close() \n",
        "  #print (label)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JBHQaPsvXYB2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class BoundingBox(object):\n",
        "    def __init__(self, dim, image_size=None):\n",
        "        # Assumes that dim are upper left corner and lower bottom corner\n",
        "        if image_size is None:\n",
        "            self.x1 = dim[0]\n",
        "            self.y1 = dim[1]\n",
        "            self.x2 = dim[2]\n",
        "            self.y2 = dim[3]\n",
        "        # Assumes we are using x_center, y_center, width, height\n",
        "        else:\n",
        "            x_center = dim[0] * image_size[0]\n",
        "            y_center = dim[1] * image_size[1]\n",
        "            width = dim[2] * image_size[0]\n",
        "            height = dim[3] * image_size[1]\n",
        "\n",
        "            self.x1 = x_center - width/2\n",
        "            self.x2 = x_center + width/2\n",
        "            self.y1 = y_center - height/2\n",
        "            self.y2 = y_center + height/2\n",
        "        \n",
        "        assert self.x1 < self.x2\n",
        "        assert self.y1 < self.y2\n",
        "\n",
        "    def __str__(self):\n",
        "        return \"({},{},{},{})\".format(self.x1, self.y1, self.x2, self.y2)\n",
        "    \n",
        "    def as_tuple(self):\n",
        "        return (self.x1, self.y1, self.x2, self.y2)\n",
        "\n",
        "    def to_yolo(self, bb2):\n",
        "        x1 = max(self.x1, bb2.x1)\n",
        "        x2 = min(self.x2, bb2.x2)\n",
        "        y1 = max(self.y1, bb2.y1)\n",
        "        y2 = min(self.y2, bb2.y2)\n",
        "        bb1 = BoundingBox((x1, y1, x2, y2))\n",
        "\n",
        "        width = bb2.x2 - bb2.x1\n",
        "        height = bb2.y2 - bb2.y1\n",
        "        \n",
        "        x_center = ((bb1.x2 + bb1.x1)/2 - bb2.x1) / (bb2.x2 - bb2.x1)\n",
        "        y_center = ((bb1.y2 + bb1.y1)/2 - bb2.y1) / (bb2.y2 - bb2.y1)\n",
        "        width = (bb1.x2-bb1.x1) / (bb2.x2 - bb2.x1)\n",
        "        height = (bb1.y2-bb1.y1) / (bb2.y2 - bb2.y1)\n",
        "        assert x_center >= 0 and x_center <= 1\n",
        "        assert y_center >= 0 and y_center <= 1\n",
        "        assert width >= 0 and width <= 1\n",
        "        assert height >= 0 and height <= 1\n",
        "        return (x_center, y_center, width, height)\n",
        "\n",
        "    # Thanks StackOverflow <3 : https://stackoverflow.com/a/42874377\n",
        "    def get_iou(self, bb2):\n",
        "        \"\"\"\n",
        "        Calculate the Intersection over Union (IoU) of two bounding boxes.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        self : BoundingBox object\n",
        "            Keys: {'x1', 'x2', 'y1', 'y2'}\n",
        "            The (x1, y1) position is at the top left corner,\n",
        "            the (x2, y2) position is at the bottom right corner\n",
        "        bb2 : BoundingBox object\n",
        "            Keys: {'x1', 'x2', 'y1', 'y2'}\n",
        "            The (x, y) position is at the top left corner,\n",
        "            the (x2, y2) position is at the bottom right corner\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        float\n",
        "            in [0, 1]\n",
        "        \"\"\"\n",
        "        assert self.x1 < self.x2\n",
        "        assert self.y1 < self.y2\n",
        "        assert bb2.x1 < bb2.x2\n",
        "        assert bb2.y1 < bb2.y2\n",
        "\n",
        "        # determine the coordinates of the intersection rectangle\n",
        "        x_left = max(self.x1, bb2.x1)\n",
        "        y_top = max(self.y1, bb2.y1)\n",
        "        x_right = min(self.x2, bb2.x2)\n",
        "        y_bottom = min(self.y2, bb2.y2)\n",
        "\n",
        "        if x_right < x_left or y_bottom < y_top:\n",
        "            return 0.0\n",
        "\n",
        "        # The intersection of two axis-aligned bounding boxes is always an\n",
        "        # axis-aligned bounding box\n",
        "        intersection_area = (x_right - x_left) * (y_bottom - y_top)\n",
        "\n",
        "        # compute the area of both AABBs\n",
        "        self_area = (self.x2 - self.x1) * (self.y2 - self.y1)\n",
        "        bb2_area = (bb2.x2 - bb2.x1) * (bb2.y2 - bb2.y1)\n",
        "\n",
        "        # compute the intersection over union by taking the intersection\n",
        "        # area and dividing it by the sum of prediction + ground-truth\n",
        "        # areas - the interesection area\n",
        "        iou = intersection_area / self_area\n",
        "        assert iou >= 0.0\n",
        "        assert iou <= 1.0\n",
        "        return iou\n",
        "\n",
        "\n",
        "\n",
        "#Resize images to max_width, max_height while maintaining aspect ratio\n",
        "#Discard small objects\n",
        "def resize_image (input_files, max_width, max_height, output_dir, discard_dir, min_sign_pixel = 100):\n",
        "\n",
        "\n",
        "    for image_file, bbox_file in input_files:\n",
        "        obj_boxes = []\n",
        "        # Calc Image size\n",
        "        im = Image.open(image_file)\n",
        "        imgwidth, imgheight = im.size\n",
        "\n",
        "        #Ratios\n",
        "        \n",
        "        width_ratio = imgwidth / max_width\n",
        "        height_ratio = imgheight / max_height\n",
        "\n",
        "        #Check if we need to resize. If image is small, skip\n",
        "        if (width_ratio < 1 and height_ratio < 1):\n",
        "          continue\n",
        "\n",
        "        #Resize by the larger ratio\n",
        "        resize_ratio = width_ratio\n",
        "        if (width_ratio < height_ratio):\n",
        "          resize_ratio = height_ratio\n",
        "\n",
        "        new_size = (int(imgwidth/resize_ratio), int(imgheight/resize_ratio))\n",
        "        new_im = im.resize(new_size)\n",
        "\n",
        "        # Get all the bounding boxes\n",
        "        # Adjust bounding boxes if necessary\n",
        "        with open(bbox_file, \"r\") as fp:\n",
        "            name, _ = os.path.splitext(os.path.basename(bbox_file))\n",
        "            #print (\"Removed object in file %s:\" % (name))\n",
        "            for line in fp:\n",
        "                # Look for image dimensions\n",
        "                numbers = re.findall(\"[0-9.]+\", line)\n",
        "                numbers = [float(x) for x in numbers]\n",
        "                if len(numbers):\n",
        "                    bbox =  BoundingBox(numbers[1:], image_size=new_size)\n",
        "\n",
        "                    #print (bbox.x2, bbox.x1, bbox.y2, bbox.y1, new_size)\n",
        "\n",
        "                    #Check if the sign would still be visible after the resize\n",
        "                    if ((bbox.x2 - bbox.x1) * (bbox.y2 - bbox.y1) < min_sign_pixel):\n",
        "                      #print (numbers)\n",
        "                      continue\n",
        "\n",
        "                    obj_boxes.append(numbers[:])\n",
        "                    #print (obj_boxes)\n",
        "\n",
        "\n",
        "        \n",
        "        if (len(obj_boxes) > 0):\n",
        "\n",
        "          new_im.save(os.path.join(output_dir, \"%s.jpg\" % (name)))\n",
        "          newline = 0  \n",
        "          with open(os.path.join(output_dir, \"%s.txt\" % (name)), \"w\") as fp:\n",
        "            for x in obj_boxes:\n",
        "              if (newline):\n",
        "                fp.write(\"\\n\")\n",
        "              str_content = \"{0:1d} {1:.6f} {2:.6f} {3:.6f} {4:.6f}\".format(int(x[0]), x[1], x[2], x[3], x[4])\n",
        "              fp.write(str_content)\n",
        "              newline = 1\n",
        "            fp.close()\n",
        "        else:\n",
        "          #print (\"Image: \", name, \" no longer has any detectable signs!\")\n",
        "          new_im.save(os.path.join(discard_dir, \"%s.jpg\" % (name)))\n",
        "\n",
        "\n",
        "\n",
        "# Break up the images into multiple overlapping sections of lower resolution.\n",
        "def break_up_image(input_files, size, stride, output_dir):\n",
        "    for image_file, bbox_file in input_files:\n",
        "        obj_boxes = []\n",
        "        # Calc Image size\n",
        "        im = Image.open(image_file)\n",
        "        imgwidth, imgheight = im.size\n",
        "\n",
        "        # Get all the bounding boxes\n",
        "        with open(bbox_file, \"r\") as fp:\n",
        "            name, _ = os.path.splitext(os.path.basename(bbox_file))\n",
        "            for line in fp:\n",
        "                # Look for image dimensions\n",
        "                numbers = re.findall(\"[0-9.]+\", line)\n",
        "                numbers = [float(x) for x in numbers]\n",
        "                if len(numbers):\n",
        "                    obj_boxes.append(BoundingBox(numbers[1:], image_size=im.size))\n",
        "        \n",
        "        # Crop\n",
        "        index = 0\n",
        "        for i in range(0, imgheight, stride):\n",
        "            for j in range(0, imgwidth, stride):\n",
        "                # Out of bounds!\n",
        "                if j+size >= imgwidth or i+size >= imgheight:\n",
        "                    continue\n",
        "                \n",
        "                crop_box = BoundingBox((j, i, j+size, i+size))\n",
        "\n",
        "                # Determine all valid object bounding boxes\n",
        "              \n",
        "                valid_obj_boxes = []\n",
        "                for obj_box in obj_boxes:\n",
        "                    if obj_box.get_iou(crop_box) >= 0.5:\n",
        "                        valid_obj_boxes.append(obj_box)\n",
        "                \n",
        "                # if there is no valid box, then we skip\n",
        "                if not valid_obj_boxes:\n",
        "                    continue\n",
        "                \n",
        "                cropped = im.crop(crop_box.as_tuple())\n",
        "                cropped.save(os.path.join(output_dir, \"%s-%s.jpg\" % (name, index)))\n",
        "\n",
        "                newline = 0\n",
        "                with open(os.path.join(output_dir, \"%s-%s.txt\" % (name, index)), \"w\") as fp:\n",
        "                  #fp.writelines([\"0 %s %s %s %s\" % x.to_yolo(crop_box) for x in valid_obj_boxes])\n",
        "                  #Might need to change the \"0\" to the actual number in the file in the future if we add more classes\n",
        "                  for x in valid_obj_boxes:\n",
        "                    if (newline):\n",
        "                      fp.write(\"\\n\")   \n",
        "                    yolo_bbox = x.to_yolo(crop_box)\n",
        "                    str_content = \"{0:1d} {1:.6f} {2:.6f} {3:.6f} {4:.6f}\".format(0, yolo_bbox[0], yolo_bbox[1], yolo_bbox[2], yolo_bbox[3])\n",
        "                    fp.write(str_content)\n",
        "                    newline = 1\n",
        "                  fp.close()\n",
        "                    \n",
        "                \n",
        "                index +=1\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ATcyLKCHzsXM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!rm -rf /content/resized/\n",
        "!rm -rf /content/discard/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RSHxW5GKoN0s",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "e08342dd-0864-4a86-a713-e0a516740536"
      },
      "source": [
        "os.makedirs(\"/content/resized\", exist_ok=True)\n",
        "os.makedirs(\"/content/discard\", exist_ok=True)\n",
        "#Sample_100/images/\n",
        "print (\"val\")\n",
        "bbox_list = sorted(glob.glob(\"/content/split_hand_selected/train/images/*.txt\"))\n",
        "images_list = sorted(glob.glob(\"/content/split_hand_selected/train/images/*.jpg\"))\n",
        "resize_image (zip(images_list, bbox_list), 1920, 1080, \"/content/resized\", \"/content/discard\", min_sign_pixel = 150)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "val\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pzz8u5ox1-ER",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!rm -rf /content/val/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UuI22q6toMmh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "os.makedirs(\"/content/train\", exist_ok=True)\n",
        "\n",
        "\n",
        "bbox_list = sorted(glob.glob(\"/content/resized/*.txt\"))\n",
        "images_list = sorted(glob.glob(\"/content/resized/*.jpg\"))\n",
        "break_up_image(zip(images_list, bbox_list), 416, 208, \"/content/train\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y7_qmJdC6tG7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b160f5d8-2f3c-4a9d-d201-d53ae80b5634"
      },
      "source": [
        "%cd /content"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pngn0LNIjnoV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ef36e606-5cdf-4b84-8cdb-c0c609afedec"
      },
      "source": [
        "!ls"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "discard  drive\tHand_Selected  resized\tsample_data  split_hand_selected  train\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xM1y0edGAAqO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "\n",
        "!zip -q -r /content/drive/'My Drive'/APS360/yolov3/Datasets/hand_selected_416x416/train.zip train\n",
        "\n",
        "!zip -q -r /content/drive/'My Drive'/APS360/yolov3/Datasets/hand_selected_416x416/train_discard.zip discard"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z4sIDIW1KJqN",
        "colab_type": "text"
      },
      "source": [
        "Train, Val, and Test SPLITTING SECTION"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ecVdPLw9bNWj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "4f5f5fbd-9707-4b30-975b-11bee59a6775"
      },
      "source": [
        "!gdown --id 1-uKo60uILmvaWTbSPVZGdP-hprLAbdd_ --output hand_selected.zip \n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1-uKo60uILmvaWTbSPVZGdP-hprLAbdd_\n",
            "To: /content/hand_selected.zip\n",
            "11.8GB [02:58, 66.1MB/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iwdANp6GK7XJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!unzip -q /content/hand_selected.zip -d /content/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dCGBC4jeP497",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "6c276b30-818e-4d74-8793-dbf32e600aac"
      },
      "source": [
        "ls /content/Hand_Selected/images/ | wc -l"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "13641\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IV4uVxBBKTK1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "4b1fc172-d821-4e0d-9f28-d3b7a261b4eb"
      },
      "source": [
        "import os, os.path\n",
        "base_dir = '/content/Hand_Selected/'\n",
        "print(\"Annotation files: {}\".format(len(os.listdir(base_dir+'annotations'))))\n",
        "print(\"image files: {}\".format(len(os.listdir(base_dir+'images'))))\n",
        "print(os.listdir(base_dir+'annotations')[0])\n",
        "print(os.listdir(base_dir+'images')[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Annotation files: 13641\n",
            "image files: 13641\n",
            "jobHCSXetCi0YHzCfO5ORg.json\n",
            "S5u_ZPE9_LHSpEmM-qfq4A.jpg\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rFMPWXlNeie5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bHVUGswPMB5N",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "6a2204bf-3399-4f2a-d68a-2844fc59b296"
      },
      "source": [
        "import os\n",
        "from glob import glob\n",
        "import shutil\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# find all image file names\n",
        "image_files = glob(base_dir+'images/*.jpg')\n",
        "image_names = [name.replace(\".jpg\",\"\").split('/')[-1] for name in image_files]\n",
        "\n",
        "# split names into 70% train, 15% val and 15% test\n",
        "train_names, test_names = train_test_split(image_names, test_size=0.3,random_state=1)\n",
        "val_names, test_names = train_test_split(test_names, test_size=0.5,random_state=1)\n",
        "print(f'Train: {len(train_names)}, Val: {len(val_names)}, Test: {len(test_names)}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train: 9548, Val: 2046, Test: 2047\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WbSyw-STe92G",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d73732b4-a43d-48b8-aef1-9a98254d5ee4"
      },
      "source": [
        "print (train_names[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1UpXUk_d1pnnUpTH0u1bbA\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RMZznDhMMI-V",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def move_files(file_names, source_path, destination_path):\n",
        "    # create dir if not exist\n",
        "    if not os.path.exists(destination_path):\n",
        "        os.makedirs(destination_path)\n",
        "    if not os.path.exists(destination_path+'images'):\n",
        "        os.makedirs(destination_path+'images')\n",
        "    if not os.path.exists(destination_path+'annotations'):\n",
        "        os.makedirs(destination_path+'annotations')\n",
        "    \n",
        "    # move images with given name\n",
        "    for fi in file_names:\n",
        "         image = fi+'.jpg'\n",
        "         json = fi+'.json'\n",
        "         \n",
        "         shutil.move(os.path.join(source_path+'images', image), \n",
        "                     os.path.join(destination_path+'images', image))\n",
        "         shutil.move(os.path.join(source_path+'annotations', json),\n",
        "                     os.path.join(destination_path+'annotations', json))\n",
        "    return\n",
        "\n",
        "#CHANGE HERE\n",
        "source_path = base_dir\n",
        "destination_path = '/content/split_hand_selected/'\n",
        "move_files(train_names,source_path,(destination_path+'train/'))\n",
        "move_files(val_names,source_path,(destination_path+'val/'))\n",
        "move_files(test_names,source_path,(destination_path+'test/'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bqfG7tP9fqrN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "76a6f61d-3da5-43ab-c099-ada32f9c7cfd"
      },
      "source": [
        "%cd split_hand_selected/"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/split_hand_selected\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-8E9Ge8DgH2w",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "dae00f8d-fe83-4f80-f41d-4cf2e652b639"
      },
      "source": [
        "!ls"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "test  train  val\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jewLCDvKfwOu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!zip -q -r /content/drive/'My Drive'/APS360/Project/Hand_Selected_Split/test.zip test "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "64us85OegUO2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!zip -q -r /content/drive/'My Drive'/APS360/Project/Hand_Selected_Split/val.zip val "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qJT-70S-gYb-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!zip -q -r /content/drive/'My Drive'/APS360/Project/Hand_Selected_Split/train.zip train "
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}